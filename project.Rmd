---
title: "compromise words project"
author: "hoskisson"
date: "2022-12-04"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Ran `auth_setup_default()` and used browser to give rtweet authentication access.
Then whenever I want to use that same authentication, I run the line `auth_as("default")` in another R file.

```{r}
library(rtweet)
library(quanteda)
library(topicmodels)
library(tidyverse)
```
```{r}
auth_as("default")
```

```{r}
rstats <- search_tweets("#rstats", n = 100, include_rts = FALSE)
colnames(rstats)
rstats[1:5, c("created_at", "text", "id_str")]
```

```{r}
# another function could try:
# lookup_tweets
collins_timeline <- get_timeline(user="SenatorCollins")

corpus_collins <- corpus(collins_timeline, 
                                     docid_field = "id",
                                     text_field = "full_text")
```


```{r}
corpus_collins_proc <- tokens(corpus_collins, 
                           remove_punct = TRUE, # remove punctuation
                           remove_numbers = TRUE, # remove numbers
                           remove_symbols = TRUE) %>% # remove symbols (for social media data, could remove everything except letters)
                        tokens_tolower() # remove capitalization
```


```{r}
lemmaData <- read.csv2("baseform_en.tsv", # downloaded from https://github.com/tm4ss/tm4ss.github.io/tree/master/resources
                       sep=",", 
                       header=FALSE, 
                       encoding = "UTF-8", 
                       stringsAsFactors = F)
```

```{r}
corpus_collins_proc <-  tokens_replace(corpus_collins_proc, # "Substitute token types based on vectorized one-to-one matching"
                                    lemmaData$V1, 
                                    lemmaData$V2,
                                    valuetype = "fixed") 

```

```{r}
corpus_collins_proc <- corpus_collins_proc %>%
                             tokens_remove(stopwords("english")) %>%
                             tokens_ngrams(1) 
```

```{r}
#  Create dtm
DTM <- dfm(corpus_collins_proc)

# Minimum
minimumFrequency <- 10
DTM <- dfm_trim(DTM, 
                min_docfreq = minimumFrequency,
                max_docfreq = 99999999)

# keep only letters... brute force
DTM  <- dfm_select(DTM, 
                   pattern = "[a-z]", 
                   valuetype = "regex", 
                   selection = 'keep')
colnames(DTM) <- stringi::stri_replace_all_regex(colnames(DTM), 
                                                 "[^_a-z]","")

DTM <- dfm_compress(DTM, "features")

# We have several rows which do not have any content left. Drop them.

sel_idx <- rowSums(DTM) > 0
DTM <- DTM[sel_idx, ]
# textdata <- textdata[sel_idx, ]
```



```{r}
K <- 5
# Set seed to make results reproducible
set.seed(9161)
topicModel <- LDA(DTM, 
                  K, 
                  method="Gibbs", 
                  control=list(iter = 500, 
                               verbose = 25))
```

```{r}
tmResult <- posterior(topicModel)


# Topics are distributions over the entire vocabulary

beta <- tmResult$terms
glimpse(beta)


# Each doc has a distribution over k topics

theta <- tmResult$topics
glimpse(theta)               

terms(topicModel, 10)

# Top terms per topic. Use top 5 to interpret topics
top5termsPerTopic <- terms(topicModel, 
                           3)
# For the next steps, we want to give the topics more descriptive names than just numbers. Therefore, we simply concatenate the five most likely terms of each topic to a string that represents a pseudo-name for each topic.
topicNames <- apply(top5termsPerTopic, 
                    2, 
                    paste, 
                    collapse=" ")
```

What are the most common themes?
```{r}

topicProportions <- colSums(theta) / nrow(DTM)  # average probability over all paragraphs
names(topicProportions) <- topicNames     # Topic Names
sort(topicProportions, decreasing = TRUE) # sort
```

```{r}
topicProportions_df <- tibble(proportions = topicProportions, topic_names = names(topicProportions))
ggplot(topicProportions_df) +
  geom_col(mapping = aes(x=proportions , y=topic_names), width=.4) +
  theme(axis.text.y = element_text(size=16, 
    color="blue", 
    face="bold",
    angle=0))
```

```{r}
topicProportions_df
```

